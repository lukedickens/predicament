{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44acde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import re\n",
    "res_digit = r'[0-9]'\n",
    "\n",
    "# fourier transform\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832db706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thisdir = /home/luke/git/external/predicament/notebooks\n",
      "Adding parent directory to python path\n",
      "sys.path =\n",
      "['/home/luke/git/external/predicament/notebooks', '/home/luke/git/external/predicament', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/luke/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "# This is a hack to make the library in the parent folder available for imoprts\n",
    "# A better solution is by np8 here:\n",
    "# https://stackoverflow.com/questions/714063/importing-modules-from-parent-folder\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "thisdir = sys.path[0]\n",
    "print(f\"thisdir = {thisdir}\")\n",
    "parentdir = os.path.dirname(thisdir)\n",
    "#print(f\"parentdir = {parentdir}\")\n",
    "if not parentdir in sys.path:\n",
    "    print(\"Adding parent directory to python path\")\n",
    "    sys.path.insert(1, parentdir)\n",
    "else:\n",
    "    print(\"Skipping adding parent direct to path (there already)\")\n",
    "\n",
    "print(f\"sys.path =\\n{sys.path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f17581",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure relative path to data directory is sound\n",
    "# for the notebook we need to modify the BASE_DATA_FOLDER\n",
    "import os \n",
    "os.environ['PREDICAMENT_DATA_DIR'] =  '../data'\n",
    "\n",
    "from predicament.utils.config import FEATURED_BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd724667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predicament.utils.file_utils import load_dataframe_and_config\n",
    "\n",
    "from predicament.evaluation.balancing import get_group_label_counts\n",
    "from predicament.evaluation.balancing import balance_data\n",
    "from predicament.evaluation.grouping import get_group_assignments\n",
    "from predicament.evaluation.staging import get_design_matrix\n",
    "from predicament.evaluation.results import output_model_best_from_results\n",
    "from predicament.evaluation.results import save_results_df_to_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e1a17",
   "metadata": {},
   "source": [
    "## Load features\n",
    "\n",
    "Before running this, you will need to generate featured data. See README file for details. For the variable `subdir` below replace this with the subdirectory name of the featured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e1ae95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fs: 64, n_samples = 256, time: 4.0s, n_channels: 7\n"
     ]
    }
   ],
   "source": [
    "subdir = '20231206193533'\n",
    "featured_data_dir = os.path.join(FEATURED_BASE_PATH,subdir)\n",
    "\n",
    "featured_df, featured_config = load_dataframe_and_config(\n",
    "    featured_data_dir, 'featured.csv')\n",
    "n_channels = int(featured_config['LOAD']['n_channels'])\n",
    "channels = json.loads(featured_config['LOAD']['channels'].replace(\"'\",'\"'))\n",
    "participant_list = json.loads(featured_config['LOAD']['participant_list'].replace(\"'\",'\"'))\n",
    "Fs = int(featured_config['LOAD']['sample_rate'])\n",
    "window_size = int(featured_config['LOAD']['window_size'])\n",
    "time = window_size/Fs\n",
    "print(f\"Fs: {Fs}, n_samples = {window_size}, time: {time}s, n_channels: {n_channels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408a74c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participant', 'condition', 'start time', 'Mean0', 'Mean1', 'Mean2',\n",
       "       'Mean3', 'Mean4', 'Mean5', 'Mean6',\n",
       "       ...\n",
       "       'FreqKurtosis4', 'FreqKurtosis5', 'FreqKurtosis6',\n",
       "       'LempelZivEntropy[b=1][0]', 'LempelZivEntropy[b=1][1]',\n",
       "       'LempelZivEntropy[b=1][2]', 'LempelZivEntropy[b=1][3]',\n",
       "       'LempelZivEntropy[b=1][4]', 'LempelZivEntropy[b=1][5]',\n",
       "       'LempelZivEntropy[b=1][6]'],\n",
       "      dtype='object', length=157)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f91ee90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before balancing: subject_condition_counts = [[ 833.  473.  473.  473.  473.]\n",
      " [ 833.  113.  353.  473.  353.]\n",
      " [ 833.  233.  473.  473.  473.]\n",
      " [ 833.  593.  353.  233.  473.]\n",
      " [   0.  113.    0. 1073.  353.]\n",
      " [ 853.  433.    0.  517.  373.]\n",
      " [ 833.  593.  473.  353.   89.]\n",
      " [ 833.  593.    0.  353.  353.]\n",
      " [ 823.  333.    0.  565.  357.]\n",
      " [ 953.  473.  353.  473.  353.]\n",
      " [ 713.  593.  473.  353.  473.]]\n",
      "after balancing: subject_condition_counts = [[296. 312. 473. 272. 287.]\n",
      " [296. 113. 353. 272. 287.]\n",
      " [296. 233. 473. 272. 287.]\n",
      " [296. 312. 353. 233. 287.]\n",
      " [  0. 113.   0. 272. 287.]\n",
      " [296. 312.   0. 272. 287.]\n",
      " [296. 312. 473. 272.  89.]\n",
      " [296. 312.   0. 272. 287.]\n",
      " [296. 312.   0. 272. 287.]\n",
      " [296. 312. 353. 272. 287.]\n",
      " [296. 312. 473. 272. 287.]]\n"
     ]
    }
   ],
   "source": [
    "# balance featured data\n",
    "subject_condition_counts = get_group_label_counts(featured_df, 'participant', 'condition')\n",
    "print(f\"before balancing: subject_condition_counts = {subject_condition_counts}\")\n",
    "featured_df = balance_data(featured_df, group_col='participant', label_col='condition')\n",
    "subject_condition_counts = get_group_label_counts(featured_df, 'participant', 'condition')\n",
    "\n",
    "print(f\"after balancing: subject_condition_counts = {subject_condition_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e3223",
   "metadata": {},
   "source": [
    "## Prepare Parameter Search Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06ccf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9fb7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_type_pairs = [('participant', 'participant'), ('condition', 'condition'), ('start time', 'start'), ('Mean0', 'Mean'), ('Mean1', 'Mean'), ('Mean2', 'Mean'), ('Mean3', 'Mean'), ('Mean4', 'Mean'), ('Mean5', 'Mean'), ('Mean6', 'Mean'), ('SD0', 'SD'), ('SD1', 'SD'), ('SD2', 'SD'), ('SD3', 'SD'), ('SD4', 'SD'), ('SD5', 'SD'), ('SD6', 'SD'), ('MAD0', 'MAD'), ('MAD1', 'MAD'), ('MAD2', 'MAD'), ('MAD3', 'MAD'), ('MAD4', 'MAD'), ('MAD5', 'MAD'), ('MAD6', 'MAD'), ('Max0', 'Max'), ('Max1', 'Max'), ('Max2', 'Max'), ('Max3', 'Max'), ('Max4', 'Max'), ('Max5', 'Max'), ('Max6', 'Max'), ('Min0', 'Min'), ('Min1', 'Min'), ('Min2', 'Min'), ('Min3', 'Min'), ('Min4', 'Min'), ('Min5', 'Min'), ('Min6', 'Min'), ('Energy0', 'Energy'), ('Energy1', 'Energy'), ('Energy2', 'Energy'), ('Energy3', 'Energy'), ('Energy4', 'Energy'), ('Energy5', 'Energy'), ('Energy6', 'Energy'), ('IQR0', 'IQR'), ('IQR1', 'IQR'), ('IQR2', 'IQR'), ('IQR3', 'IQR'), ('IQR4', 'IQR'), ('IQR5', 'IQR'), ('IQR6', 'IQR'), ('Correlation0', 'Correlation'), ('Correlation1', 'Correlation'), ('Correlation2', 'Correlation'), ('Correlation3', 'Correlation'), ('Correlation4', 'Correlation'), ('Correlation5', 'Correlation'), ('Correlation6', 'Correlation'), ('Correlation7', 'Correlation'), ('Correlation8', 'Correlation'), ('Correlation9', 'Correlation'), ('Correlation10', 'Correlation'), ('Correlation11', 'Correlation'), ('Correlation12', 'Correlation'), ('Correlation13', 'Correlation'), ('Correlation14', 'Correlation'), ('Correlation15', 'Correlation'), ('Correlation16', 'Correlation'), ('Correlation17', 'Correlation'), ('Correlation18', 'Correlation'), ('Correlation19', 'Correlation'), ('Correlation20', 'Correlation'), ('arCoeff0', 'arCoeff'), ('arCoeff1', 'arCoeff'), ('arCoeff2', 'arCoeff'), ('arCoeff3', 'arCoeff'), ('arCoeff4', 'arCoeff'), ('arCoeff5', 'arCoeff'), ('arCoeff6', 'arCoeff'), ('arCoeff7', 'arCoeff'), ('arCoeff8', 'arCoeff'), ('arCoeff9', 'arCoeff'), ('arCoeff10', 'arCoeff'), ('arCoeff11', 'arCoeff'), ('arCoeff12', 'arCoeff'), ('arCoeff13', 'arCoeff'), ('arCoeff14', 'arCoeff'), ('arCoeff15', 'arCoeff'), ('arCoeff16', 'arCoeff'), ('arCoeff17', 'arCoeff'), ('arCoeff18', 'arCoeff'), ('arCoeff19', 'arCoeff'), ('arCoeff20', 'arCoeff'), ('arCoeff21', 'arCoeff'), ('arCoeff22', 'arCoeff'), ('arCoeff23', 'arCoeff'), ('arCoeff24', 'arCoeff'), ('arCoeff25', 'arCoeff'), ('arCoeff26', 'arCoeff'), ('arCoeff27', 'arCoeff'), ('Hurst_H0', 'Hurst'), ('Hurst_H1', 'Hurst'), ('Hurst_H2', 'Hurst'), ('Hurst_H3', 'Hurst'), ('Hurst_H4', 'Hurst'), ('Hurst_H5', 'Hurst'), ('Hurst_H6', 'Hurst'), ('Hurst_C0', 'Hurst'), ('Hurst_C1', 'Hurst'), ('Hurst_C2', 'Hurst'), ('Hurst_C3', 'Hurst'), ('Hurst_C4', 'Hurst'), ('Hurst_C5', 'Hurst'), ('Hurst_C6', 'Hurst'), ('LyapunovExponent0', 'LyapunovExponent'), ('LyapunovExponent1', 'LyapunovExponent'), ('LyapunovExponent2', 'LyapunovExponent'), ('LyapunovExponent3', 'LyapunovExponent'), ('LyapunovExponent4', 'LyapunovExponent'), ('LyapunovExponent5', 'LyapunovExponent'), ('LyapunovExponent6', 'LyapunovExponent'), ('MaxFreqInd0', 'MaxFreqInd'), ('MaxFreqInd1', 'MaxFreqInd'), ('MaxFreqInd2', 'MaxFreqInd'), ('MaxFreqInd3', 'MaxFreqInd'), ('MaxFreqInd4', 'MaxFreqInd'), ('MaxFreqInd5', 'MaxFreqInd'), ('MaxFreqInd6', 'MaxFreqInd'), ('MeanFreq0', 'MeanFreq'), ('MeanFreq1', 'MeanFreq'), ('MeanFreq2', 'MeanFreq'), ('MeanFreq3', 'MeanFreq'), ('MeanFreq4', 'MeanFreq'), ('MeanFreq5', 'MeanFreq'), ('MeanFreq6', 'MeanFreq'), ('FreqSkewness0', 'FreqSkewness'), ('FreqSkewness1', 'FreqSkewness'), ('FreqSkewness2', 'FreqSkewness'), ('FreqSkewness3', 'FreqSkewness'), ('FreqSkewness4', 'FreqSkewness'), ('FreqSkewness5', 'FreqSkewness'), ('FreqSkewness6', 'FreqSkewness'), ('FreqKurtosis0', 'FreqKurtosis'), ('FreqKurtosis1', 'FreqKurtosis'), ('FreqKurtosis2', 'FreqKurtosis'), ('FreqKurtosis3', 'FreqKurtosis'), ('FreqKurtosis4', 'FreqKurtosis'), ('FreqKurtosis5', 'FreqKurtosis'), ('FreqKurtosis6', 'FreqKurtosis'), ('LempelZivEntropy[b=1][0]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][1]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][2]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][3]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][4]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][5]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][6]', 'LempelZivEntropy')]\n",
      "feature_names = ['Mean0', 'Mean1', 'Mean2', 'Mean3', 'Mean4', 'Mean5', 'Mean6', 'SD0', 'SD1', 'SD2', 'SD3', 'SD4', 'SD5', 'SD6', 'MAD0', 'MAD1', 'MAD2', 'MAD3', 'MAD4', 'MAD5', 'MAD6', 'Max0', 'Max1', 'Max2', 'Max3', 'Max4', 'Max5', 'Max6', 'Min0', 'Min1', 'Min2', 'Min3', 'Min4', 'Min5', 'Min6', 'Energy0', 'Energy1', 'Energy2', 'Energy3', 'Energy4', 'Energy5', 'Energy6', 'IQR0', 'IQR1', 'IQR2', 'IQR3', 'IQR4', 'IQR5', 'IQR6', 'Correlation0', 'Correlation1', 'Correlation2', 'Correlation3', 'Correlation4', 'Correlation5', 'Correlation6', 'Correlation7', 'Correlation8', 'Correlation9', 'Correlation10', 'Correlation11', 'Correlation12', 'Correlation13', 'Correlation14', 'Correlation15', 'Correlation16', 'Correlation17', 'Correlation18', 'Correlation19', 'Correlation20', 'arCoeff0', 'arCoeff1', 'arCoeff2', 'arCoeff3', 'arCoeff4', 'arCoeff5', 'arCoeff6', 'arCoeff7', 'arCoeff8', 'arCoeff9', 'arCoeff10', 'arCoeff11', 'arCoeff12', 'arCoeff13', 'arCoeff14', 'arCoeff15', 'arCoeff16', 'arCoeff17', 'arCoeff18', 'arCoeff19', 'arCoeff20', 'arCoeff21', 'arCoeff22', 'arCoeff23', 'arCoeff24', 'arCoeff25', 'arCoeff26', 'arCoeff27', 'Hurst_H0', 'Hurst_H1', 'Hurst_H2', 'Hurst_H3', 'Hurst_H4', 'Hurst_H5', 'Hurst_H6', 'Hurst_C0', 'Hurst_C1', 'Hurst_C2', 'Hurst_C3', 'Hurst_C4', 'Hurst_C5', 'Hurst_C6', 'LyapunovExponent0', 'LyapunovExponent1', 'LyapunovExponent2', 'LyapunovExponent3', 'LyapunovExponent4', 'LyapunovExponent5', 'LyapunovExponent6', 'MaxFreqInd0', 'MaxFreqInd1', 'MaxFreqInd2', 'MaxFreqInd3', 'MaxFreqInd4', 'MaxFreqInd5', 'MaxFreqInd6', 'MeanFreq0', 'MeanFreq1', 'MeanFreq2', 'MeanFreq3', 'MeanFreq4', 'MeanFreq5', 'MeanFreq6', 'FreqSkewness0', 'FreqSkewness1', 'FreqSkewness2', 'FreqSkewness3', 'FreqSkewness4', 'FreqSkewness5', 'FreqSkewness6', 'FreqKurtosis0', 'FreqKurtosis1', 'FreqKurtosis2', 'FreqKurtosis3', 'FreqKurtosis4', 'FreqKurtosis5', 'FreqKurtosis6', 'LempelZivEntropy[b=1][0]', 'LempelZivEntropy[b=1][1]', 'LempelZivEntropy[b=1][2]', 'LempelZivEntropy[b=1][3]', 'LempelZivEntropy[b=1][4]', 'LempelZivEntropy[b=1][5]', 'LempelZivEntropy[b=1][6]']\n",
      "feature_type_pairs = [('participant', 'participant'), ('condition', 'condition'), ('start time', 'start'), ('Mean0', 'Mean'), ('Mean1', 'Mean'), ('Mean2', 'Mean'), ('Mean3', 'Mean'), ('Mean4', 'Mean'), ('Mean5', 'Mean'), ('Mean6', 'Mean'), ('SD0', 'SD'), ('SD1', 'SD'), ('SD2', 'SD'), ('SD3', 'SD'), ('SD4', 'SD'), ('SD5', 'SD'), ('SD6', 'SD'), ('MAD0', 'MAD'), ('MAD1', 'MAD'), ('MAD2', 'MAD'), ('MAD3', 'MAD'), ('MAD4', 'MAD'), ('MAD5', 'MAD'), ('MAD6', 'MAD'), ('Max0', 'Max'), ('Max1', 'Max'), ('Max2', 'Max'), ('Max3', 'Max'), ('Max4', 'Max'), ('Max5', 'Max'), ('Max6', 'Max'), ('Min0', 'Min'), ('Min1', 'Min'), ('Min2', 'Min'), ('Min3', 'Min'), ('Min4', 'Min'), ('Min5', 'Min'), ('Min6', 'Min'), ('Energy0', 'Energy'), ('Energy1', 'Energy'), ('Energy2', 'Energy'), ('Energy3', 'Energy'), ('Energy4', 'Energy'), ('Energy5', 'Energy'), ('Energy6', 'Energy'), ('IQR0', 'IQR'), ('IQR1', 'IQR'), ('IQR2', 'IQR'), ('IQR3', 'IQR'), ('IQR4', 'IQR'), ('IQR5', 'IQR'), ('IQR6', 'IQR'), ('Correlation0', 'Correlation'), ('Correlation1', 'Correlation'), ('Correlation2', 'Correlation'), ('Correlation3', 'Correlation'), ('Correlation4', 'Correlation'), ('Correlation5', 'Correlation'), ('Correlation6', 'Correlation'), ('Correlation7', 'Correlation'), ('Correlation8', 'Correlation'), ('Correlation9', 'Correlation'), ('Correlation10', 'Correlation'), ('Correlation11', 'Correlation'), ('Correlation12', 'Correlation'), ('Correlation13', 'Correlation'), ('Correlation14', 'Correlation'), ('Correlation15', 'Correlation'), ('Correlation16', 'Correlation'), ('Correlation17', 'Correlation'), ('Correlation18', 'Correlation'), ('Correlation19', 'Correlation'), ('Correlation20', 'Correlation'), ('arCoeff0', 'arCoeff'), ('arCoeff1', 'arCoeff'), ('arCoeff2', 'arCoeff'), ('arCoeff3', 'arCoeff'), ('arCoeff4', 'arCoeff'), ('arCoeff5', 'arCoeff'), ('arCoeff6', 'arCoeff'), ('arCoeff7', 'arCoeff'), ('arCoeff8', 'arCoeff'), ('arCoeff9', 'arCoeff'), ('arCoeff10', 'arCoeff'), ('arCoeff11', 'arCoeff'), ('arCoeff12', 'arCoeff'), ('arCoeff13', 'arCoeff'), ('arCoeff14', 'arCoeff'), ('arCoeff15', 'arCoeff'), ('arCoeff16', 'arCoeff'), ('arCoeff17', 'arCoeff'), ('arCoeff18', 'arCoeff'), ('arCoeff19', 'arCoeff'), ('arCoeff20', 'arCoeff'), ('arCoeff21', 'arCoeff'), ('arCoeff22', 'arCoeff'), ('arCoeff23', 'arCoeff'), ('arCoeff24', 'arCoeff'), ('arCoeff25', 'arCoeff'), ('arCoeff26', 'arCoeff'), ('arCoeff27', 'arCoeff'), ('Hurst_H0', 'Hurst'), ('Hurst_H1', 'Hurst'), ('Hurst_H2', 'Hurst'), ('Hurst_H3', 'Hurst'), ('Hurst_H4', 'Hurst'), ('Hurst_H5', 'Hurst'), ('Hurst_H6', 'Hurst'), ('Hurst_C0', 'Hurst'), ('Hurst_C1', 'Hurst'), ('Hurst_C2', 'Hurst'), ('Hurst_C3', 'Hurst'), ('Hurst_C4', 'Hurst'), ('Hurst_C5', 'Hurst'), ('Hurst_C6', 'Hurst'), ('LyapunovExponent0', 'LyapunovExponent'), ('LyapunovExponent1', 'LyapunovExponent'), ('LyapunovExponent2', 'LyapunovExponent'), ('LyapunovExponent3', 'LyapunovExponent'), ('LyapunovExponent4', 'LyapunovExponent'), ('LyapunovExponent5', 'LyapunovExponent'), ('LyapunovExponent6', 'LyapunovExponent'), ('MaxFreqInd0', 'MaxFreqInd'), ('MaxFreqInd1', 'MaxFreqInd'), ('MaxFreqInd2', 'MaxFreqInd'), ('MaxFreqInd3', 'MaxFreqInd'), ('MaxFreqInd4', 'MaxFreqInd'), ('MaxFreqInd5', 'MaxFreqInd'), ('MaxFreqInd6', 'MaxFreqInd'), ('MeanFreq0', 'MeanFreq'), ('MeanFreq1', 'MeanFreq'), ('MeanFreq2', 'MeanFreq'), ('MeanFreq3', 'MeanFreq'), ('MeanFreq4', 'MeanFreq'), ('MeanFreq5', 'MeanFreq'), ('MeanFreq6', 'MeanFreq'), ('FreqSkewness0', 'FreqSkewness'), ('FreqSkewness1', 'FreqSkewness'), ('FreqSkewness2', 'FreqSkewness'), ('FreqSkewness3', 'FreqSkewness'), ('FreqSkewness4', 'FreqSkewness'), ('FreqSkewness5', 'FreqSkewness'), ('FreqSkewness6', 'FreqSkewness'), ('FreqKurtosis0', 'FreqKurtosis'), ('FreqKurtosis1', 'FreqKurtosis'), ('FreqKurtosis2', 'FreqKurtosis'), ('FreqKurtosis3', 'FreqKurtosis'), ('FreqKurtosis4', 'FreqKurtosis'), ('FreqKurtosis5', 'FreqKurtosis'), ('FreqKurtosis6', 'FreqKurtosis'), ('LempelZivEntropy[b=1][0]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][1]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][2]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][3]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][4]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][5]', 'LempelZivEntropy'), ('LempelZivEntropy[b=1][6]', 'LempelZivEntropy')]\n"
     ]
    }
   ],
   "source": [
    "# model name\n",
    "name = 'RandomForest'\n",
    "\n",
    "# extract input data\n",
    "feature_types, feature_names, designmtx = get_design_matrix(featured_df)\n",
    "# extract labels\n",
    "condition_data = featured_df['condition'].values.astype(int)\n",
    "\n",
    "# prepare Hold one group out cross validation\n",
    "held_out = 'participant'\n",
    "held_out, groups, group_assignments = get_group_assignments(featured_df)\n",
    "n_groups = len(groups)\n",
    "# cross validation splits    \n",
    "group_kfold = GroupKFold(n_splits=n_groups)\n",
    "\n",
    "# choose which search to perform\n",
    "# search_type = 'random_search'\n",
    "search_type = 'bayesian_optimization'\n",
    "# number of iterations for your search\n",
    "n_iter = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d15480",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "\n",
    "If `search_type == 'random_search'`, we use a random grid to search for best hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15feda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if search_type == 'random_search':\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False] \n",
    "    # Create the random grid\n",
    "    random_grid = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'bootstrap': bootstrap}\n",
    "\n",
    "    # First create the base model to tune\n",
    "    estimator = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    param_search = RandomizedSearchCV(\n",
    "        estimator = estimator,\n",
    "        param_distributions = random_grid,\n",
    "        n_iter = n_iter,\n",
    "        cv=group_kfold,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        n_jobs = -1)\n",
    "\n",
    "    # Fit the random search model\n",
    "    _ = param_search.fit(X=designmtx, y=condition_data, groups=group_assignments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d210bd",
   "metadata": {},
   "source": [
    "## Bayesian Optimisation\n",
    "\n",
    "If `search_type == 'bayesian_optimization'`, we use a Bayesian Optimisation search for best hyperparameters. Should be quicker and more effective than random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff5afcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 1 candidates, totalling 11 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 1 candidates, totalling 11 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  5.7min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 1 candidates, totalling 11 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 1 candidates, totalling 11 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 1 candidates, totalling 11 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Bayesian optimisation\n",
    "\n",
    "if search_type == 'bayesian_optimization':\n",
    "\n",
    "    # this is just a naive initial guess at what will work\n",
    "    # note that the log-uniform prior helps to focus on \n",
    "    # smaller values\n",
    "    search_spaces = dict(\n",
    "        # Number of trees in random forest\n",
    "        n_estimators = Integer(10,2000, prior='log-uniform'),\n",
    "        # Number of features to consider at every split\n",
    "        max_features = Categorical(['auto', 'sqrt']),\n",
    "        # Maximum number of levels in tree\n",
    "        max_depth = Integer(1, 200,  prior='log-uniform'),\n",
    "        # Minimum number of samples required at each leaf node\n",
    "        min_samples_leaf = Real(1e-4, 1e-2, prior='log-uniform'),\n",
    "        # Method of selecting samples for training each tree\n",
    "        bootstrap = Categorical([True, False])\n",
    "    )\n",
    "\n",
    "    estimator = RandomForestClassifier()\n",
    "    # log-uniform: understand as search over p = exp(x) by varying x\n",
    "    param_search = BayesSearchCV(\n",
    "        estimator, search_spaces,\n",
    "        cv=group_kfold, verbose=2, random_state=42, n_iter=n_iter,\n",
    "        n_jobs = -1)\n",
    "\n",
    "    # executes bayesian optimization\n",
    "    _ = param_search.fit(X=designmtx, y=condition_data, groups=group_assignments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61972264",
   "metadata": {},
   "source": [
    "## Saving and outputing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceedbcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>held out</th>\n",
       "      <th>feature set</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>participant</td>\n",
       "      <td>{'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...</td>\n",
       "      <td>80.860373</td>\n",
       "      <td>5.315280</td>\n",
       "      <td>0.087075</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255908</td>\n",
       "      <td>0.368932</td>\n",
       "      <td>0.289932</td>\n",
       "      <td>0.271637</td>\n",
       "      <td>0.335047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037202</td>\n",
       "      <td>0.250137</td>\n",
       "      <td>0.156475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>participant</td>\n",
       "      <td>{'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...</td>\n",
       "      <td>112.571651</td>\n",
       "      <td>6.588301</td>\n",
       "      <td>0.226844</td>\n",
       "      <td>0.057989</td>\n",
       "      <td>True</td>\n",
       "      <td>108</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256583</td>\n",
       "      <td>0.386269</td>\n",
       "      <td>0.211961</td>\n",
       "      <td>0.276778</td>\n",
       "      <td>0.371894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069940</td>\n",
       "      <td>0.241407</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>participant</td>\n",
       "      <td>{'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...</td>\n",
       "      <td>6.493225</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>False</td>\n",
       "      <td>130</td>\n",
       "      <td>auto</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167454</td>\n",
       "      <td>0.325243</td>\n",
       "      <td>0.143830</td>\n",
       "      <td>0.282776</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.101190</td>\n",
       "      <td>0.226939</td>\n",
       "      <td>0.155173</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>participant</td>\n",
       "      <td>{'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...</td>\n",
       "      <td>5.968149</td>\n",
       "      <td>0.394589</td>\n",
       "      <td>0.032742</td>\n",
       "      <td>0.008793</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256583</td>\n",
       "      <td>0.378641</td>\n",
       "      <td>0.090083</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.245930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219426</td>\n",
       "      <td>0.144537</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>participant</td>\n",
       "      <td>{'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...</td>\n",
       "      <td>151.915508</td>\n",
       "      <td>7.300137</td>\n",
       "      <td>0.292973</td>\n",
       "      <td>0.068554</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251857</td>\n",
       "      <td>0.384189</td>\n",
       "      <td>0.242998</td>\n",
       "      <td>0.275064</td>\n",
       "      <td>0.305056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141369</td>\n",
       "      <td>0.237144</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model     held out  \\\n",
       "0  RandomForestClassifier()  participant   \n",
       "1  RandomForestClassifier()  participant   \n",
       "2  RandomForestClassifier()  participant   \n",
       "3  RandomForestClassifier()  participant   \n",
       "4  RandomForestClassifier()  participant   \n",
       "\n",
       "                                         feature set  mean_fit_time  \\\n",
       "0  {'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...      80.860373   \n",
       "1  {'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...     112.571651   \n",
       "2  {'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...       6.493225   \n",
       "3  {'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...       5.968149   \n",
       "4  {'Energy', 'LempelZivEntropy', 'MAD', 'IQR', '...     151.915508   \n",
       "\n",
       "   std_fit_time  mean_score_time  std_score_time param_bootstrap  \\\n",
       "0      5.315280         0.087075        0.018155           False   \n",
       "1      6.588301         0.226844        0.057989            True   \n",
       "2      0.515957         0.008298        0.002013           False   \n",
       "3      0.394589         0.032742        0.008793            True   \n",
       "4      7.300137         0.292973        0.068554            True   \n",
       "\n",
       "  param_max_depth param_max_features  ... split4_test_score split5_test_score  \\\n",
       "0              47               sqrt  ...          0.255908          0.368932   \n",
       "1             108               auto  ...          0.256583          0.386269   \n",
       "2             130               auto  ...          0.167454          0.325243   \n",
       "3               2               sqrt  ...          0.256583          0.378641   \n",
       "4              10               sqrt  ...          0.251857          0.384189   \n",
       "\n",
       "  split6_test_score  split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0          0.289932           0.271637           0.335047           0.000000   \n",
       "1          0.211961           0.276778           0.371894           0.000000   \n",
       "2          0.143830           0.282776           0.373608           0.003428   \n",
       "3          0.090083           0.248500           0.245930           0.000000   \n",
       "4          0.242998           0.275064           0.305056           0.000000   \n",
       "\n",
       "   split10_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.037202         0.250137        0.156475                1  \n",
       "1            0.069940         0.241407        0.156945                2  \n",
       "2            0.101190         0.226939        0.155173                4  \n",
       "3            0.000000         0.219426        0.144537                5  \n",
       "4            0.141369         0.237144        0.132369                3  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to ../data/results/bayesian_optimization_RandomForest_2023-12-28T19:06:57.csv\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(param_search.cv_results_)\n",
    "result_df.insert(0, 'model', str(estimator))\n",
    "result_df.insert(1, 'held out', held_out)\n",
    "result_df.insert(2, 'feature set', str(feature_types))\n",
    "display(result_df)\n",
    "save_results_df_to_file(result_df, f'{search_type}_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e34752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(): max_test_score= 0.2501365821568324, max_std_test_score= 0.15647530693538286\n",
      "best params: OrderedDict([('bootstrap', False), ('max_depth', 47), ('max_features', 'sqrt'), ('min_samples_leaf', 0.0004281531928076346), ('n_estimators', 348)])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = output_model_best_from_results(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6e5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
